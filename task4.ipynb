{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM55/qngq0HrfdAFNmzDo+a",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/muqeetahmaad9/student-performance-internship/blob/main/task4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_rj4Kq9M0OuX",
        "outputId": "39e40577-9ad6-4257-d69b-563d7b23ab2d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "user_item_matrix shape: (943, 1682)\n",
            "User-based CF recommendations for user 1:\n",
            "423 - E.T. the Extra-Terrestrial (1982) (score: 3.666)\n",
            "474 - Dr. Strangelove or: How I Learned to Stop Worrying and Love the Bomb (1963) (score: 3.453)\n",
            "655 - Stand by Me (1986) (score: 3.442)\n",
            "568 - Speed (1994) (score: 3.237)\n",
            "403 - Batman (1989) (score: 3.201)\n",
            "357 - One Flew Over the Cuckoo's Nest (1975) (score: 3.106)\n",
            "385 - True Lies (1994) (score: 3.099)\n",
            "318 - Schindler's List (1993) (score: 3.000)\n",
            "651 - Glory (1989) (score: 2.998)\n",
            "433 - Heathers (1989) (score: 2.984)\n",
            "\n",
            "Item-based CF recommendations for user 1:\n",
            "423 - E.T. the Extra-Terrestrial (1982) (score: 394.094)\n",
            "655 - Stand by Me (1986) (score: 368.217)\n",
            "568 - Speed (1994) (score: 367.805)\n",
            "403 - Batman (1989) (score: 364.944)\n",
            "385 - True Lies (1994) (score: 363.508)\n",
            "318 - Schindler's List (1993) (score: 357.974)\n",
            "357 - One Flew Over the Cuckoo's Nest (1975) (score: 352.764)\n",
            "367 - Clueless (1995) (score: 351.735)\n",
            "393 - Mrs. Doubtfire (1993) (score: 345.905)\n",
            "433 - Heathers (1989) (score: 345.832)\n",
            "\n",
            "SVD-based recommendations for user 1:\n",
            "285 - Secrets & Lies (1996) (score: 4.589)\n",
            "318 - Schindler's List (1993) (score: 4.588)\n",
            "455 - Jackie Chan's First Strike (1996) (score: 4.485)\n",
            "323 - Dante's Peak (1997) (score: 4.435)\n",
            "421 - William Shakespeare's Romeo and Juliet (1996) (score: 4.346)\n",
            "462 - Like Water For Chocolate (Como agua para chocolate) (1992) (score: 4.343)\n",
            "357 - One Flew Over the Cuckoo's Nest (1975) (score: 4.234)\n",
            "511 - Lawrence of Arabia (1962) (score: 4.190)\n",
            "762 - Beautiful Girls (1996) (score: 4.176)\n",
            "652 - Rosencrantz and Guildenstern Are Dead (1990) (score: 4.159)\n",
            "\n",
            "Computing Precision@10 (sample users)...\n",
            "Precision@10 (User-based CF): 0.0\n",
            "\n",
            "User 1 - User-CF recs:\n",
            "  E.T. the Extra-Terrestrial (1982) (movie_id=423, score=3.666)\n",
            "  Dr. Strangelove or: How I Learned to Stop Worrying and Love the Bomb (1963) (movie_id=474, score=3.453)\n",
            "  Stand by Me (1986) (movie_id=655, score=3.442)\n",
            "  Speed (1994) (movie_id=568, score=3.237)\n",
            "  Batman (1989) (movie_id=403, score=3.201)\n",
            "\n",
            "User 50 - User-CF recs:\n",
            "  Star Wars (1977) (movie_id=50, score=2.912)\n",
            "  Twelve Monkeys (1995) (movie_id=7, score=2.508)\n",
            "  Secrets & Lies (1996) (movie_id=285, score=2.327)\n",
            "  Contact (1997) (movie_id=258, score=2.223)\n",
            "  Godfather, The (1972) (movie_id=127, score=2.206)\n",
            "\n",
            "User 100 - User-CF recs:\n",
            "  Devil's Advocate, The (1997) (movie_id=307, score=2.917)\n",
            "  Cop Land (1997) (movie_id=327, score=2.185)\n",
            "  Edge, The (1997) (movie_id=331, score=2.128)\n",
            "  In & Out (1997) (movie_id=301, score=1.904)\n",
            "  Kiss the Girls (1997) (movie_id=332, score=1.867)\n",
            "\n",
            "User 200 - User-CF recs:\n",
            "  Return of the Jedi (1983) (movie_id=181, score=4.442)\n",
            "  Monty Python and the Holy Grail (1974) (movie_id=168, score=3.973)\n",
            "  Blues Brothers, The (1980) (movie_id=186, score=3.617)\n",
            "  Clear and Present Danger (1994) (movie_id=566, score=3.408)\n",
            "  Batman (1989) (movie_id=403, score=3.336)\n"
          ]
        }
      ],
      "source": [
        "# Task5: Movie Recommendation System (Colab-ready)\n",
        "# Run in Google Colab\n",
        "\n",
        "# 0. Install / Import (no extra installs required)\n",
        "import os\n",
        "import zipfile\n",
        "import urllib.request\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.preprocessing import normalize\n",
        "from sklearn.decomposition import TruncatedSVD\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# 1. Download MovieLens 100K\n",
        "data_url = \"http://files.grouplens.org/datasets/movielens/ml-100k.zip\"\n",
        "zip_path = \"/content/ml-100k.zip\"\n",
        "if not os.path.exists(\"/content/ml-100k\"):\n",
        "    print(\"Downloading MovieLens 100k...\")\n",
        "    urllib.request.urlretrieve(data_url, zip_path)\n",
        "    with zipfile.ZipFile(zip_path, 'r') as z:\n",
        "        z.extractall(\"/content/ml-100k\")\n",
        "    print(\"Done.\")\n",
        "\n",
        "# 2. Load ratings and movie titles\n",
        "# u.data format: user id | item id | rating | timestamp\n",
        "ratings_path = \"/content/ml-100k/ml-100k/u.data\"\n",
        "columns = ['user_id', 'movie_id', 'rating', 'timestamp']\n",
        "ratings = pd.read_csv(ratings_path, sep='\\t', names=columns, encoding='latin-1')\n",
        "\n",
        "# u.item contains movie id | movie title | ...\n",
        "items_path = \"/content/ml-100k/ml-100k/u.item\"\n",
        "movies = pd.read_csv(items_path, sep='|', names=range(24), encoding='latin-1', header=None)\n",
        "movies = movies[[0, 1]]  # first two columns: id, title\n",
        "movies.columns = ['movie_id', 'title']\n",
        "movies['movie_id'] = movies['movie_id'].astype(int)\n",
        "\n",
        "# Merge for readability when showing recommendations\n",
        "ratings = ratings.merge(movies, on='movie_id', how='left')\n",
        "\n",
        "# 3. Create user-item matrix (pivot)\n",
        "user_item = ratings.pivot_table(index='user_id', columns='movie_id', values='rating').fillna(0)\n",
        "user_item_matrix = user_item.values  # shape (n_users, n_items)\n",
        "print(\"user_item_matrix shape:\", user_item_matrix.shape)\n",
        "\n",
        "# Helper: mapping ids to indices\n",
        "user_ids = list(user_item.index)\n",
        "movie_ids = list(user_item.columns)\n",
        "movie_id_to_col = {mid: idx for idx, mid in enumerate(movie_ids)}\n",
        "col_to_movie_id = {idx: mid for idx, mid in enumerate(movie_ids)}\n",
        "movieid_to_title = dict(zip(movies['movie_id'], movies['title']))\n",
        "\n",
        "# 4. USER-BASED Collaborative Filtering (cosine similarity)\n",
        "# compute user-user cosine similarity\n",
        "user_sim = cosine_similarity(user_item_matrix)  # (n_users, n_users)\n",
        "\n",
        "def recommend_user_based(target_user_id, top_k=10, n_neighbors=20):\n",
        "    \"\"\"\n",
        "    Recommend top_k movies for target_user_id using user-based CF\n",
        "    n_neighbors: number of similar users to consider\n",
        "    \"\"\"\n",
        "    if target_user_id not in user_ids:\n",
        "        raise ValueError(\"User id not in dataset\")\n",
        "\n",
        "    u_idx = user_ids.index(target_user_id)\n",
        "    sim_scores = user_sim[u_idx]  # similarity to all users\n",
        "    # ignore self\n",
        "    sim_scores[u_idx] = 0\n",
        "    # find top neighbors\n",
        "    neighbors_idx = np.argsort(sim_scores)[-n_neighbors:]\n",
        "    neighbor_sims = sim_scores[neighbors_idx]\n",
        "\n",
        "    # Weighted sum of neighbor ratings\n",
        "    neighbor_ratings = user_item_matrix[neighbors_idx]  # shape (n_neighbors, n_items)\n",
        "    weighted_sum = np.dot(neighbor_sims, neighbor_ratings)\n",
        "    sim_sum = np.sum(np.abs(neighbor_sims)) + 1e-9\n",
        "    predicted_scores = weighted_sum / sim_sum\n",
        "\n",
        "    # Mask already rated items by target user\n",
        "    rated = user_item_matrix[u_idx] > 0\n",
        "    predicted_scores[rated] = -np.inf\n",
        "\n",
        "    # pick top_k movie indices\n",
        "    top_indices = np.argsort(predicted_scores)[-top_k:][::-1]\n",
        "    recommendations = [(col_to_movie_id[i], movieid_to_title[col_to_movie_id[i]], predicted_scores[i]) for i in top_indices]\n",
        "    return recommendations\n",
        "\n",
        "# Example: recommend for user 1\n",
        "print(\"User-based CF recommendations for user 1:\")\n",
        "for mid, title, score in recommend_user_based(1, top_k=10, n_neighbors=30):\n",
        "    print(f\"{mid} - {title} (score: {score:.3f})\")\n",
        "\n",
        "# 5. ITEM-BASED Collaborative Filtering (bonus)\n",
        "# compute item-item similarity based on columns of user_item_matrix\n",
        "item_item = cosine_similarity(user_item_matrix.T)  # (n_items, n_items)\n",
        "\n",
        "def recommend_item_based(target_user_id, top_k=10, n_sim_items=20):\n",
        "    u_idx = user_ids.index(target_user_id)\n",
        "    user_ratings = user_item_matrix[u_idx]  # ratings by the user\n",
        "    # For each item user has rated, get similar items\n",
        "    scores = np.zeros(user_item_matrix.shape[1])\n",
        "    for item_idx, r in enumerate(user_ratings):\n",
        "        if r > 0:\n",
        "            sim_items = item_item[item_idx] # similarity of current item to all items\n",
        "            # Take top similar items (excluding self)\n",
        "            top_sim_idx = np.argsort(sim_items)[-n_sim_items-1:-1] # Exclude the item itself\n",
        "            # Predict score for each unrated item based on similarity to rated item\n",
        "            # and the user's rating of that item\n",
        "            # We only consider items the user *hasn't* rated yet for recommendations\n",
        "            unrated_items_idx = np.where(user_ratings == 0)[0]\n",
        "            for unrated_item_idx in unrated_items_idx:\n",
        "                # Find similarity between the rated item and the unrated item\n",
        "                similarity = item_item[item_idx, unrated_item_idx]\n",
        "                scores[unrated_item_idx] += similarity * r\n",
        "\n",
        "    # Mask already seen (already handled by only adding to unrated items)\n",
        "    # Mask items that received no prediction (no similar rated items)\n",
        "    scores[user_ratings > 0] = -np.inf # ensure already rated items are not recommended\n",
        "    scores[scores == 0] = -np.inf # ensure items with no similar rated items are not recommended\n",
        "\n",
        "    top_indices = np.argsort(scores)[-top_k:][::-1]\n",
        "    recommendations = [(col_to_movie_id[i], movieid_to_title[col_to_movie_id[i]], scores[i]) for i in top_indices if scores[i] > -np.inf]\n",
        "    return recommendations\n",
        "\n",
        "\n",
        "print(\"\\nItem-based CF recommendations for user 1:\")\n",
        "for mid, title, score in recommend_item_based(1, top_k=10, n_sim_items=30):\n",
        "    print(f\"{mid} - {title} (score: {score:.3f})\")\n",
        "\n",
        "# 6. SVD (Matrix Factorization) using TruncatedSVD (bonus)\n",
        "# We'll use user-item sparse representation (centered)\n",
        "from scipy.sparse import csr_matrix\n",
        "\n",
        "# Center ratings by subtracting user mean to improve SVD performance\n",
        "user_means = np.true_divide(user_item_matrix.sum(axis=1), (user_item_matrix > 0).sum(axis=1) + 1e-9)\n",
        "R_centered = user_item_matrix - user_means.reshape(-1, 1)\n",
        "R_centered[np.where(user_item_matrix == 0)] = 0  # keep zeros for missing\n",
        "\n",
        "svd = TruncatedSVD(n_components=50, random_state=42)\n",
        "U = svd.fit_transform(R_centered)           # user factors (n_users x k)\n",
        "Sigma = svd.singular_values_                # singular values\n",
        "VT = svd.components_                        # item factors (k x n_items)\n",
        "\n",
        "# Reconstruct approximate ratings (add back user means)\n",
        "R_hat = np.dot(U, VT) + user_means.reshape(-1, 1)\n",
        "\n",
        "def recommend_svd(target_user_id, top_k=10):\n",
        "    u_idx = user_ids.index(target_user_id)\n",
        "    preds = R_hat[u_idx]\n",
        "    rated = user_item_matrix[u_idx] > 0\n",
        "    preds[rated] = -np.inf\n",
        "    top_indices = np.argsort(preds)[-top_k:][::-1]\n",
        "    recommendations = [(col_to_movie_id[i], movieid_to_title[col_to_movie_id[i]], preds[i]) for i in top_indices]\n",
        "    return recommendations\n",
        "\n",
        "print(\"\\nSVD-based recommendations for user 1:\")\n",
        "for mid, title, score in recommend_svd(1, top_k=10):\n",
        "    print(f\"{mid} - {title} (score: {score:.3f})\")\n",
        "\n",
        "# 7. EVALUATION: Precision@K for user-based CF\n",
        "# Build train/test split of ratings (leave-one-out style or holdout)\n",
        "def prepare_train_test(ratings_df, test_size=0.2, random_state=42):\n",
        "    train_df, test_df = train_test_split(ratings_df, test_size=test_size, random_state=random_state)\n",
        "    # build matrices\n",
        "    train_mat = train_df.pivot_table(index='user_id', columns='movie_id', values='rating').reindex(index=user_item.index, columns=user_item.columns).fillna(0)\n",
        "    test_mat = test_df.pivot_table(index='user_id', columns='movie_id', values='rating').reindex(index=user_item.index, columns=user_item.columns).fillna(0)\n",
        "    return train_mat.values, test_mat.values\n",
        "\n",
        "train_mat, test_mat = prepare_train_test(ratings, test_size=0.2)\n",
        "\n",
        "# compute user similarity on train\n",
        "train_user_sim = cosine_similarity(train_mat)\n",
        "\n",
        "def precision_at_k_from_matrix(pred_func, train_mat, test_mat, K=10, n_users_eval=100):\n",
        "    \"\"\"\n",
        "    pred_func(user_id) should return list of recommended movie_ids (top K)\n",
        "    train_mat/test_mat: matrices aligned to user_ids and movie_ids\n",
        "    \"\"\"\n",
        "    n_users = train_mat.shape[0]\n",
        "    users_to_eval = range(min(n_users, n_users_eval))\n",
        "    precisions = []\n",
        "    for u in users_to_eval:\n",
        "        # get ground truth items in test (relevant items)\n",
        "        relevant = set(np.where(test_mat[u] > 0)[0])  # column indices\n",
        "        if len(relevant) == 0:\n",
        "            continue\n",
        "        # get top-K recommendations using function adapted to indexed user\n",
        "        # Our pred_func expects user_id from original ids; convert\n",
        "        uid = user_ids[u]\n",
        "        recs = pred_func(uid, top_k=K)\n",
        "        rec_item_indices = [movie_ids.index(mid) for mid, _, _ in recs if mid in movie_ids]\n",
        "        hit = len(set(rec_item_indices).intersection(relevant))\n",
        "        precisions.append(hit / K)\n",
        "    return np.mean(precisions)\n",
        "\n",
        "# Wrap recommender to match signature\n",
        "def user_cf_wrapper(uid, top_k=10):\n",
        "    return recommend_user_based(uid, top_k=top_k, n_neighbors=30)\n",
        "\n",
        "print(\"\\nComputing Precision@10 (sample users)...\")\n",
        "p_at_10 = precision_at_k_from_matrix(user_cf_wrapper, train_mat, test_mat, K=10, n_users_eval=200)\n",
        "print(\"Precision@10 (User-based CF):\", round(p_at_10, 4))\n",
        "\n",
        "# 8. Save results / show a sample of recommendations for several users\n",
        "sample_users = [1, 50, 100, 200]\n",
        "for u in sample_users:\n",
        "    print(f\"\\nUser {u} - User-CF recs:\")\n",
        "    for mid, title, score in recommend_user_based(u, top_k=5, n_neighbors=30):\n",
        "        print(f\"  {title} (movie_id={mid}, score={score:.3f})\")"
      ]
    }
  ]
}